# Acknowlegements

**Thanks to the following resources for providing invouluable free insights... Because of them, I was able to build this project. It's true that we always build on the back of giants.**

Meta FAIR for the original implementation of Large Language Models. This project is a direct implementation of their two-tower latent diffusion architecture.
- [Meta FAIR](https://github.com/facebookresearch/fair-lcm)

3Blue1Brown for his videos that helped me understand the concepts and math behind transformers.
- [3Blue1Brown](https://www.youtube.com/@3blue1brown)

Ebad Sayed for their Medium articles that helped me understand the coding of transformers... and I was heavily inspired on how to even start this Transformers version by their code too üôèüèº!
- [Ebad Sayed](https://medium.com/@sayedebad.777)

**And most of all, the entire open-source community, without whom the world woud be a darker and more selfish place. Most of the internet is built on their generosity and gregarious commitment to sharing their knowledge and work with the world.**